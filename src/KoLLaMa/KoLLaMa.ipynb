{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# KoLLaMa\n",
    "Large Language Model Meta AI\n",
    "\n",
    "[HuggingFace beomi/kollama-7b](https://huggingface.co/beomi/kollama-7b)\n",
    "AutoModelForCausalLM 사용\n",
    "\n",
    "- CausalLM(Causal Language Model, 인과적 언어모형): 조건부 확률 형태의 언어모형\n",
    "\t- 인공신경망 등의 모형으로 구현하기 쉬움\n",
    "\t- 단어를 순서대로 생성할 수 있음\n",
    "\n",
    "[preprocess.ipynb](/datas/KoLLaMa/Dataset.csv)에서 위의 KcELECTRA에서 사용한 Dataset.csv를 수정해 문장과 순서가 뒤섞인 문장으로 이루어진 새로운 Dataset.csv 파일을 생성함.\n",
    "\n",
    "BBPE Tokenizer 사용\n",
    "- Byte-level Byte Pair Encoding\n",
    "\n",
    "KoLLaMa-7b fine tuning 후 실행"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b88b7838969c2ec8"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## environment"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "483f2d3aa5135ec1"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "from src.Common.common import *\n",
    "\n",
    "# Dataset.csv\n",
    "import pandas as pd\n",
    "\n",
    "# HuggingFace\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, TrainingArguments, Trainer\n",
    "\n",
    "# PyTorch\n",
    "from torch.utils.data import Dataset"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-08T07:16:11.583612100Z",
     "start_time": "2023-08-08T07:16:08.156362700Z"
    }
   },
   "id": "8e10c18400fb6973"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "c = CommonObj()\n",
    "\n",
    "c.KoLLaMa_MODEL_NAME = \"beomi/kollama-7b\"\n",
    "c.SAVED_MODEL_NAME = \"../../models/KcELECTRA\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-08T07:16:16.464821Z",
     "start_time": "2023-08-08T07:16:16.462308200Z"
    }
   },
   "id": "7dbb9a00cc8bf8e"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "   Unnamed: 0                                              mixed  \\\n0           0  이종석 한효주 나오는 드라마 이후로 드라마 안봤다. 2년전인가?? 좀 신선했었지. ...   \n1           1                    꽂등심이다ㅠㅜ 저녁은 오늘 술프노... 씨바알..노무노무   \n2           2                                           꺼라ㅡ패쓰 짱깨   \n3           3  그들의 사생활 지금 ~ 설리를 위해서라도 모두 조용하길 고인이된 누굴 탓한다고 무슨...   \n4           4  아무리 법이 공공의 무슨 자격으로 개인의 신상정보를 불특정 다수에게 안되네요 도저히...   \n\n                                           not_mixed  \n0  이종석 한효주 나오는 드라마 이후로 드라마 안봤다. 2년전인가?? 좀 신선했었지. ...  \n1                    씨바알..노무노무 술프노... 오늘 저녁은 꽂등심이다ㅠㅜ  \n2                                           짱깨 꺼라ㅡ패쓰  \n3  그들의 사생활 ~ 고인이된 설리를 위해서라도 모두 조용하길 지금 누굴 탓한다고 무슨...  \n4  아무리 법이 뭣같아도 무슨 자격으로 개인의 신상정보를 불특정 다수에게 공개하는지 도...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>mixed</th>\n      <th>not_mixed</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>이종석 한효주 나오는 드라마 이후로 드라마 안봤다. 2년전인가?? 좀 신선했었지. ...</td>\n      <td>이종석 한효주 나오는 드라마 이후로 드라마 안봤다. 2년전인가?? 좀 신선했었지. ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>꽂등심이다ㅠㅜ 저녁은 오늘 술프노... 씨바알..노무노무</td>\n      <td>씨바알..노무노무 술프노... 오늘 저녁은 꽂등심이다ㅠㅜ</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>꺼라ㅡ패쓰 짱깨</td>\n      <td>짱깨 꺼라ㅡ패쓰</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>그들의 사생활 지금 ~ 설리를 위해서라도 모두 조용하길 고인이된 누굴 탓한다고 무슨...</td>\n      <td>그들의 사생활 ~ 고인이된 설리를 위해서라도 모두 조용하길 지금 누굴 탓한다고 무슨...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>아무리 법이 공공의 무슨 자격으로 개인의 신상정보를 불특정 다수에게 안되네요 도저히...</td>\n      <td>아무리 법이 뭣같아도 무슨 자격으로 개인의 신상정보를 불특정 다수에게 공개하는지 도...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.df = pd.read_csv(\"../../datas/KoLLaMa/Dataset.csv\", sep = \"\\t\")\n",
    "c.df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-08T07:16:20.420073200Z",
     "start_time": "2023-08-08T07:16:20.380734800Z"
    }
   },
   "id": "b3a699b88bd676e3"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Train set / Test set"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "16ef09529a5385a4"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data length 8000\n",
      "Test data length 2000\n"
     ]
    }
   ],
   "source": [
    "c.train_data = c.df.sample(frac = 0.8, random_state = 42)\n",
    "c.test_data = c.df.drop(c.train_data.index)\n",
    "\n",
    "print(f\"Train data length {len(c.train_data)}\")\n",
    "print(f\"Test data length {len(c.test_data)}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-08T07:16:22.861568700Z",
     "start_time": "2023-08-08T07:16:22.855375500Z"
    }
   },
   "id": "a824272ac96d1ca4"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Tokenizer"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b0cacf47f3e395a5"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "PreTrainedTokenizerFast(name_or_path='beomi/kollama-7b', vocab_size=52000, model_max_length=1000000000000000019884624838656, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<|sep|>', 'eos_token': '<|endoftext|>', 'pad_token': '<|endoftext|>'}, clean_up_tokenization_spaces=True)"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.tokenizer = AutoTokenizer.from_pretrained(c.KoLLaMa_MODEL_NAME, device_map = \"auto\")\n",
    "# c.tokenizer = AutoTokenizer.from_pretrained(c.SAVED_MODEL_NAME, device_map = \"auto\")\n",
    "\n",
    "c.tokenizer"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-08T07:16:25.000665600Z",
     "start_time": "2023-08-08T07:16:24.710785100Z"
    }
   },
   "id": "2e1476601b06a76"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Train data Tokenized"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d5e969c0d8a302b8"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "c.tokenized_train_X = c.tokenizer(\n",
    "    list(c.train_data[\"mixed\"]),\n",
    "    return_tensors = \"pt\",\n",
    "\tmax_length = 128,\n",
    "\tpadding = True,\n",
    "\ttruncation = True,\n",
    "\tadd_special_tokens = True\n",
    ")\n",
    "\n",
    "c.tokenized_train_y = c.tokenizer(\n",
    "    list(c.train_data[\"not_mixed\"]),\n",
    "    return_tensors = \"pt\",\n",
    "\tmax_length = 128,\n",
    "\tpadding = True,\n",
    "\ttruncation = True,\n",
    "\tadd_special_tokens = True\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-08T07:16:28.845807200Z",
     "start_time": "2023-08-08T07:16:28.148196800Z"
    }
   },
   "id": "674e9d323629ae7e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Test data Tokenized"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3cd12b2a3630ac25"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "c.tokenized_test_X = c.tokenizer(\n",
    "    list(c.test_data[\"mixed\"]),\n",
    "    return_tensors = \"pt\",\n",
    "\tmax_length = 128,\n",
    "\tpadding = True,\n",
    "\ttruncation = True,\n",
    "\tadd_special_tokens = True\n",
    ")\n",
    "\n",
    "c.tokenized_test_y = c.tokenizer(\n",
    "    list(c.test_data[\"not_mixed\"]),\n",
    "    return_tensors = \"pt\",\n",
    "\tmax_length = 128,\n",
    "\tpadding = True,\n",
    "\ttruncation = True,\n",
    "\tadd_special_tokens = True\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-08T07:16:29.386862100Z",
     "start_time": "2023-08-08T07:16:29.246890700Z"
    }
   },
   "id": "76d6855a758100b1"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding(num_tokens=128, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing])\n",
      "['ê½Ĥ', 'ëĵ±', 'ìĭ¬', 'ìĿ´ëĭ¤', 'áħ²', 'áħ®', 'ĠìłĢëħģ', 'ìĿĢ', 'Ġìĺ¤ëĬĺ', 'ĠìĪł', 'íĶĦ', 'ëħ¸', '...', 'ĠìĶ¨', 'ë°Ķ', 'ìķĮ', '..', 'ëħ¸', 'ë¬´ë', 'ħ¸', 'ë¬´', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>']\n",
      "Encoding(num_tokens=128, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing])\n",
      "['ìĶ¨', 'ë°Ķ', 'ìķĮ', '..', 'ëħ¸', 'ë¬´ë', 'ħ¸', 'ë¬´', 'ĠìĪł', 'íĶĦ', 'ëħ¸', '...', 'Ġìĺ¤ëĬĺ', 'ĠìłĢëħģ', 'ìĿĢ', 'Ġê½Ĥ', 'ëĵ±', 'ìĭ¬', 'ìĿ´ëĭ¤', 'áħ²', 'áħ®', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>']\n"
     ]
    }
   ],
   "source": [
    "print(c.tokenized_test_X[0])\n",
    "print(c.tokenized_test_X[0].tokens)\n",
    "print(c.tokenized_test_y[0])\n",
    "print(c.tokenized_test_y[0].tokens)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-08T07:16:30.561470900Z",
     "start_time": "2023-08-08T07:16:30.558608400Z"
    }
   },
   "id": "4dd60d4dc66a1a3f"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "꽂등심이다ᅲᅮ 저녁은 오늘 술프노... 씨바알..노무노무<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>\n"
     ]
    }
   ],
   "source": [
    "print(c.tokenizer.convert_tokens_to_string(c.tokenized_test_X[0].tokens))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-08T07:16:31.495976700Z",
     "start_time": "2023-08-08T07:16:31.491100Z"
    }
   },
   "id": "99beec05187b32f8"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Custom Dataset\n",
    "\n",
    "#### 1. Dataset\n",
    "torch.utils.data.Dataset을 상속한 클래스를 직접 구현해 데이터 load 방식을 직접 설정\n",
    "\n",
    "\n",
    "#### 2. DataLoader\n",
    "torch.utils.data.DataLoader 클래스를 직접 사용\n",
    "`train_dataloader = DataLoader((train_X, train_y), batch_size = 4, shuffle = True)`"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a26f14418ef3545a"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "\tdef __init__(self, data_X, data_y):\n",
    "\t\tself.train_data = []\n",
    "\t\tfor x, y in zip(data_X[\"input_ids\"],data_y[\"input_ids\"]):\n",
    "\t\t\tself.train_data.append((x, y))\n",
    "\t\n",
    "\tdef __len__(self):\n",
    "\t\treturn len(self.train_data)\n",
    "\t\n",
    "\tdef __getitem__(self, idx):\n",
    "\t\tX, y = self.train_data[idx]\n",
    "\t\treturn X.clone().detach(), y.clone().detach()\n",
    "\n",
    "c.train_dataset = CustomDataset(c.tokenized_train_X, c.tokenized_train_y)\n",
    "c.test_dataset = CustomDataset(c.tokenized_test_X, c.tokenized_test_y)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-08T07:16:38.054564400Z",
     "start_time": "2023-08-08T07:16:37.975100800Z"
    }
   },
   "id": "ecce82e29e52fd96"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Training Arguments"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "949bbbda091e567d"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "c.training_args = TrainingArguments(\n",
    "\toutput_dir = \"./\",\n",
    "\tnum_train_epochs = 10,\n",
    "\tper_device_train_batch_size = 8,\n",
    "\tper_device_eval_batch_size = 64,\n",
    "\tlogging_dir = \"./logs\",\n",
    "\tlogging_steps = 500, # 학습 log 기록 단위\n",
    "\tlog_level = \"warning\", # default\n",
    "\tsave_total_limit = 2 # 학습 결과 저장 최대 갯수\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-08T07:16:41.188816300Z",
     "start_time": "2023-08-08T07:16:41.176647200Z"
    }
   },
   "id": "d296dd941b84eb23"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Model Load"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "30af47706da015bf"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "Loading checkpoint shards:   0%|          | 0/15 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8ce0dd45f1424a60a59acede5542fac5"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 172.00 MiB (GPU 0; 12.00 GiB total capacity; 11.21 GiB already allocated; 0 bytes free; 11.21 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mOutOfMemoryError\u001B[0m                          Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[12], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m c\u001B[38;5;241m.\u001B[39mmodel \u001B[38;5;241m=\u001B[39m \u001B[43mAutoModelForCausalLM\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfrom_pretrained\u001B[49m\u001B[43m(\u001B[49m\u001B[43mc\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mKoLLaMa_MODEL_NAME\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_labels\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m2\u001B[39;49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mto\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mcuda:0\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m      2\u001B[0m \u001B[38;5;66;03m# c.model = AutoModelForCausalLM.from_pretrained(c.SAVED_MODEL_NAME, num_labels = 2).to(\"cuda:0\")\u001B[39;00m\n\u001B[0;32m      4\u001B[0m c\u001B[38;5;241m.\u001B[39mmodel\n",
      "File \u001B[1;32m~\\PycharmProjects\\NLP\\venv\\Lib\\site-packages\\transformers\\modeling_utils.py:1900\u001B[0m, in \u001B[0;36mPreTrainedModel.to\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1895\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m   1896\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m`.to` is not supported for `4-bit` or `8-bit` models. Please use the model as it is, since the\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   1897\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m model has already been set to the correct devices and casted to the correct `dtype`.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   1898\u001B[0m     )\n\u001B[0;32m   1899\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1900\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mto\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\PycharmProjects\\NLP\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1145\u001B[0m, in \u001B[0;36mModule.to\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1141\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m t\u001B[38;5;241m.\u001B[39mto(device, dtype \u001B[38;5;28;01mif\u001B[39;00m t\u001B[38;5;241m.\u001B[39mis_floating_point() \u001B[38;5;129;01mor\u001B[39;00m t\u001B[38;5;241m.\u001B[39mis_complex() \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[0;32m   1142\u001B[0m                     non_blocking, memory_format\u001B[38;5;241m=\u001B[39mconvert_to_format)\n\u001B[0;32m   1143\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m t\u001B[38;5;241m.\u001B[39mto(device, dtype \u001B[38;5;28;01mif\u001B[39;00m t\u001B[38;5;241m.\u001B[39mis_floating_point() \u001B[38;5;129;01mor\u001B[39;00m t\u001B[38;5;241m.\u001B[39mis_complex() \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m, non_blocking)\n\u001B[1;32m-> 1145\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_apply\u001B[49m\u001B[43m(\u001B[49m\u001B[43mconvert\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\PycharmProjects\\NLP\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:797\u001B[0m, in \u001B[0;36mModule._apply\u001B[1;34m(self, fn)\u001B[0m\n\u001B[0;32m    795\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_apply\u001B[39m(\u001B[38;5;28mself\u001B[39m, fn):\n\u001B[0;32m    796\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m module \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mchildren():\n\u001B[1;32m--> 797\u001B[0m         \u001B[43mmodule\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_apply\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfn\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    799\u001B[0m     \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mcompute_should_use_set_data\u001B[39m(tensor, tensor_applied):\n\u001B[0;32m    800\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m torch\u001B[38;5;241m.\u001B[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001B[0;32m    801\u001B[0m             \u001B[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001B[39;00m\n\u001B[0;32m    802\u001B[0m             \u001B[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    807\u001B[0m             \u001B[38;5;66;03m# global flag to let the user control whether they want the future\u001B[39;00m\n\u001B[0;32m    808\u001B[0m             \u001B[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001B[39;00m\n",
      "File \u001B[1;32m~\\PycharmProjects\\NLP\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:797\u001B[0m, in \u001B[0;36mModule._apply\u001B[1;34m(self, fn)\u001B[0m\n\u001B[0;32m    795\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_apply\u001B[39m(\u001B[38;5;28mself\u001B[39m, fn):\n\u001B[0;32m    796\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m module \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mchildren():\n\u001B[1;32m--> 797\u001B[0m         \u001B[43mmodule\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_apply\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfn\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    799\u001B[0m     \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mcompute_should_use_set_data\u001B[39m(tensor, tensor_applied):\n\u001B[0;32m    800\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m torch\u001B[38;5;241m.\u001B[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001B[0;32m    801\u001B[0m             \u001B[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001B[39;00m\n\u001B[0;32m    802\u001B[0m             \u001B[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    807\u001B[0m             \u001B[38;5;66;03m# global flag to let the user control whether they want the future\u001B[39;00m\n\u001B[0;32m    808\u001B[0m             \u001B[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001B[39;00m\n",
      "    \u001B[1;31m[... skipping similar frames: Module._apply at line 797 (2 times)]\u001B[0m\n",
      "File \u001B[1;32m~\\PycharmProjects\\NLP\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:797\u001B[0m, in \u001B[0;36mModule._apply\u001B[1;34m(self, fn)\u001B[0m\n\u001B[0;32m    795\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_apply\u001B[39m(\u001B[38;5;28mself\u001B[39m, fn):\n\u001B[0;32m    796\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m module \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mchildren():\n\u001B[1;32m--> 797\u001B[0m         \u001B[43mmodule\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_apply\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfn\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    799\u001B[0m     \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mcompute_should_use_set_data\u001B[39m(tensor, tensor_applied):\n\u001B[0;32m    800\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m torch\u001B[38;5;241m.\u001B[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001B[0;32m    801\u001B[0m             \u001B[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001B[39;00m\n\u001B[0;32m    802\u001B[0m             \u001B[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    807\u001B[0m             \u001B[38;5;66;03m# global flag to let the user control whether they want the future\u001B[39;00m\n\u001B[0;32m    808\u001B[0m             \u001B[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001B[39;00m\n",
      "File \u001B[1;32m~\\PycharmProjects\\NLP\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:820\u001B[0m, in \u001B[0;36mModule._apply\u001B[1;34m(self, fn)\u001B[0m\n\u001B[0;32m    816\u001B[0m \u001B[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001B[39;00m\n\u001B[0;32m    817\u001B[0m \u001B[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001B[39;00m\n\u001B[0;32m    818\u001B[0m \u001B[38;5;66;03m# `with torch.no_grad():`\u001B[39;00m\n\u001B[0;32m    819\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mno_grad():\n\u001B[1;32m--> 820\u001B[0m     param_applied \u001B[38;5;241m=\u001B[39m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[43mparam\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    821\u001B[0m should_use_set_data \u001B[38;5;241m=\u001B[39m compute_should_use_set_data(param, param_applied)\n\u001B[0;32m    822\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m should_use_set_data:\n",
      "File \u001B[1;32m~\\PycharmProjects\\NLP\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1143\u001B[0m, in \u001B[0;36mModule.to.<locals>.convert\u001B[1;34m(t)\u001B[0m\n\u001B[0;32m   1140\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m convert_to_format \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m t\u001B[38;5;241m.\u001B[39mdim() \u001B[38;5;129;01min\u001B[39;00m (\u001B[38;5;241m4\u001B[39m, \u001B[38;5;241m5\u001B[39m):\n\u001B[0;32m   1141\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m t\u001B[38;5;241m.\u001B[39mto(device, dtype \u001B[38;5;28;01mif\u001B[39;00m t\u001B[38;5;241m.\u001B[39mis_floating_point() \u001B[38;5;129;01mor\u001B[39;00m t\u001B[38;5;241m.\u001B[39mis_complex() \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[0;32m   1142\u001B[0m                 non_blocking, memory_format\u001B[38;5;241m=\u001B[39mconvert_to_format)\n\u001B[1;32m-> 1143\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mt\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mto\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mt\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mis_floating_point\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mt\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mis_complex\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnon_blocking\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[1;31mOutOfMemoryError\u001B[0m: CUDA out of memory. Tried to allocate 172.00 MiB (GPU 0; 12.00 GiB total capacity; 11.21 GiB already allocated; 0 bytes free; 11.21 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "c.model = AutoModelForCausalLM.from_pretrained(c.KoLLaMa_MODEL_NAME, num_labels = 2).to(\"cuda:0\")\n",
    "# c.model = AutoModelForCausalLM.from_pretrained(c.SAVED_MODEL_NAME, num_labels = 2).to(\"cuda:0\")\n",
    "\n",
    "c.model"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-08T07:19:33.032248800Z",
     "start_time": "2023-08-08T07:16:43.801420900Z"
    }
   },
   "id": "91e8f88c671946de"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Memory 딸려 시부럴~"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "26c1311ce1776af5"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'CommonObj' object has no attribute 'model'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[13], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[43mc\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[38;5;241m.\u001B[39mhf_device_map)\n",
      "\u001B[1;31mAttributeError\u001B[0m: 'CommonObj' object has no attribute 'model'"
     ]
    }
   ],
   "source": [
    "print(c.model.hf_device_map)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-08T07:19:48.328050900Z",
     "start_time": "2023-08-08T07:19:48.300693100Z"
    }
   },
   "id": "209f945bb496bc4c"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Trainer"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "97fa8582d31476e2"
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "Cannot copy out of meta tensor; no data!",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNotImplementedError\u001B[0m                       Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[82], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m c\u001B[38;5;241m.\u001B[39mtrainer \u001B[38;5;241m=\u001B[39m \u001B[43mTrainer\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m      2\u001B[0m \u001B[43m\t\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mc\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      3\u001B[0m \u001B[43m\t\u001B[49m\u001B[43margs\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mc\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtraining_args\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      4\u001B[0m \u001B[43m\t\u001B[49m\u001B[43mtrain_dataset\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mc\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain_dataset\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      5\u001B[0m \u001B[43m\t\u001B[49m\u001B[43meval_dataset\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mc\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtest_dataset\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      6\u001B[0m \u001B[43m\t\u001B[49m\u001B[43mcompute_metrics\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mcompute_metrics\u001B[49m\n\u001B[0;32m      7\u001B[0m \u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\PycharmProjects\\NLP\\venv\\Lib\\site-packages\\transformers\\trainer.py:499\u001B[0m, in \u001B[0;36mTrainer.__init__\u001B[1;34m(self, model, args, data_collator, train_dataset, eval_dataset, tokenizer, model_init, compute_metrics, callbacks, optimizers, preprocess_logits_for_metrics)\u001B[0m\n\u001B[0;32m    497\u001B[0m \u001B[38;5;66;03m# Quantized models doesn't support `.to` operation.\u001B[39;00m\n\u001B[0;32m    498\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mplace_model_on_device \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mgetattr\u001B[39m(model, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mis_quantized\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mFalse\u001B[39;00m):\n\u001B[1;32m--> 499\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_move_model_to_device\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdevice\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    501\u001B[0m \u001B[38;5;66;03m# Force n_gpu to 1 to avoid DataParallel as MP will manage the GPUs\u001B[39;00m\n\u001B[0;32m    502\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mis_model_parallel:\n",
      "File \u001B[1;32m~\\PycharmProjects\\NLP\\venv\\Lib\\site-packages\\transformers\\trainer.py:741\u001B[0m, in \u001B[0;36mTrainer._move_model_to_device\u001B[1;34m(self, model, device)\u001B[0m\n\u001B[0;32m    740\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_move_model_to_device\u001B[39m(\u001B[38;5;28mself\u001B[39m, model, device):\n\u001B[1;32m--> 741\u001B[0m     model \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mto\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    742\u001B[0m     \u001B[38;5;66;03m# Moving a model to an XLA device disconnects the tied weights, so we have to retie them.\u001B[39;00m\n\u001B[0;32m    743\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39margs\u001B[38;5;241m.\u001B[39mparallel_mode \u001B[38;5;241m==\u001B[39m ParallelMode\u001B[38;5;241m.\u001B[39mTPU \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(model, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtie_weights\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n",
      "File \u001B[1;32m~\\PycharmProjects\\NLP\\venv\\Lib\\site-packages\\transformers\\modeling_utils.py:1900\u001B[0m, in \u001B[0;36mPreTrainedModel.to\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1895\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m   1896\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m`.to` is not supported for `4-bit` or `8-bit` models. Please use the model as it is, since the\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   1897\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m model has already been set to the correct devices and casted to the correct `dtype`.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   1898\u001B[0m     )\n\u001B[0;32m   1899\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1900\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mto\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\PycharmProjects\\NLP\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1145\u001B[0m, in \u001B[0;36mModule.to\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1141\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m t\u001B[38;5;241m.\u001B[39mto(device, dtype \u001B[38;5;28;01mif\u001B[39;00m t\u001B[38;5;241m.\u001B[39mis_floating_point() \u001B[38;5;129;01mor\u001B[39;00m t\u001B[38;5;241m.\u001B[39mis_complex() \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[0;32m   1142\u001B[0m                     non_blocking, memory_format\u001B[38;5;241m=\u001B[39mconvert_to_format)\n\u001B[0;32m   1143\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m t\u001B[38;5;241m.\u001B[39mto(device, dtype \u001B[38;5;28;01mif\u001B[39;00m t\u001B[38;5;241m.\u001B[39mis_floating_point() \u001B[38;5;129;01mor\u001B[39;00m t\u001B[38;5;241m.\u001B[39mis_complex() \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m, non_blocking)\n\u001B[1;32m-> 1145\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_apply\u001B[49m\u001B[43m(\u001B[49m\u001B[43mconvert\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\PycharmProjects\\NLP\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:797\u001B[0m, in \u001B[0;36mModule._apply\u001B[1;34m(self, fn)\u001B[0m\n\u001B[0;32m    795\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_apply\u001B[39m(\u001B[38;5;28mself\u001B[39m, fn):\n\u001B[0;32m    796\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m module \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mchildren():\n\u001B[1;32m--> 797\u001B[0m         \u001B[43mmodule\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_apply\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfn\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    799\u001B[0m     \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mcompute_should_use_set_data\u001B[39m(tensor, tensor_applied):\n\u001B[0;32m    800\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m torch\u001B[38;5;241m.\u001B[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001B[0;32m    801\u001B[0m             \u001B[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001B[39;00m\n\u001B[0;32m    802\u001B[0m             \u001B[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    807\u001B[0m             \u001B[38;5;66;03m# global flag to let the user control whether they want the future\u001B[39;00m\n\u001B[0;32m    808\u001B[0m             \u001B[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001B[39;00m\n",
      "File \u001B[1;32m~\\PycharmProjects\\NLP\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:797\u001B[0m, in \u001B[0;36mModule._apply\u001B[1;34m(self, fn)\u001B[0m\n\u001B[0;32m    795\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_apply\u001B[39m(\u001B[38;5;28mself\u001B[39m, fn):\n\u001B[0;32m    796\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m module \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mchildren():\n\u001B[1;32m--> 797\u001B[0m         \u001B[43mmodule\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_apply\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfn\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    799\u001B[0m     \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mcompute_should_use_set_data\u001B[39m(tensor, tensor_applied):\n\u001B[0;32m    800\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m torch\u001B[38;5;241m.\u001B[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001B[0;32m    801\u001B[0m             \u001B[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001B[39;00m\n\u001B[0;32m    802\u001B[0m             \u001B[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    807\u001B[0m             \u001B[38;5;66;03m# global flag to let the user control whether they want the future\u001B[39;00m\n\u001B[0;32m    808\u001B[0m             \u001B[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001B[39;00m\n",
      "    \u001B[1;31m[... skipping similar frames: Module._apply at line 797 (2 times)]\u001B[0m\n",
      "File \u001B[1;32m~\\PycharmProjects\\NLP\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:797\u001B[0m, in \u001B[0;36mModule._apply\u001B[1;34m(self, fn)\u001B[0m\n\u001B[0;32m    795\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_apply\u001B[39m(\u001B[38;5;28mself\u001B[39m, fn):\n\u001B[0;32m    796\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m module \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mchildren():\n\u001B[1;32m--> 797\u001B[0m         \u001B[43mmodule\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_apply\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfn\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    799\u001B[0m     \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mcompute_should_use_set_data\u001B[39m(tensor, tensor_applied):\n\u001B[0;32m    800\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m torch\u001B[38;5;241m.\u001B[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001B[0;32m    801\u001B[0m             \u001B[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001B[39;00m\n\u001B[0;32m    802\u001B[0m             \u001B[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    807\u001B[0m             \u001B[38;5;66;03m# global flag to let the user control whether they want the future\u001B[39;00m\n\u001B[0;32m    808\u001B[0m             \u001B[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001B[39;00m\n",
      "File \u001B[1;32m~\\PycharmProjects\\NLP\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:820\u001B[0m, in \u001B[0;36mModule._apply\u001B[1;34m(self, fn)\u001B[0m\n\u001B[0;32m    816\u001B[0m \u001B[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001B[39;00m\n\u001B[0;32m    817\u001B[0m \u001B[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001B[39;00m\n\u001B[0;32m    818\u001B[0m \u001B[38;5;66;03m# `with torch.no_grad():`\u001B[39;00m\n\u001B[0;32m    819\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mno_grad():\n\u001B[1;32m--> 820\u001B[0m     param_applied \u001B[38;5;241m=\u001B[39m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[43mparam\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    821\u001B[0m should_use_set_data \u001B[38;5;241m=\u001B[39m compute_should_use_set_data(param, param_applied)\n\u001B[0;32m    822\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m should_use_set_data:\n",
      "File \u001B[1;32m~\\PycharmProjects\\NLP\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1143\u001B[0m, in \u001B[0;36mModule.to.<locals>.convert\u001B[1;34m(t)\u001B[0m\n\u001B[0;32m   1140\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m convert_to_format \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m t\u001B[38;5;241m.\u001B[39mdim() \u001B[38;5;129;01min\u001B[39;00m (\u001B[38;5;241m4\u001B[39m, \u001B[38;5;241m5\u001B[39m):\n\u001B[0;32m   1141\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m t\u001B[38;5;241m.\u001B[39mto(device, dtype \u001B[38;5;28;01mif\u001B[39;00m t\u001B[38;5;241m.\u001B[39mis_floating_point() \u001B[38;5;129;01mor\u001B[39;00m t\u001B[38;5;241m.\u001B[39mis_complex() \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[0;32m   1142\u001B[0m                 non_blocking, memory_format\u001B[38;5;241m=\u001B[39mconvert_to_format)\n\u001B[1;32m-> 1143\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mt\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mto\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mt\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mis_floating_point\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mt\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mis_complex\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnon_blocking\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[1;31mNotImplementedError\u001B[0m: Cannot copy out of meta tensor; no data!"
     ]
    }
   ],
   "source": [
    "c.trainer = Trainer(\n",
    "\tmodel = c.model,\n",
    "\targs = c.training_args,\n",
    "\ttrain_dataset = c.train_dataset,\n",
    "\teval_dataset = c.test_dataset,\n",
    "\tcompute_metrics = compute_metrics\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-08T07:14:34.805453Z",
     "start_time": "2023-08-08T07:14:34.110099400Z"
    }
   },
   "id": "7af5ee185653c1f"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "del c"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-08T07:19:57.278932900Z",
     "start_time": "2023-08-08T07:19:57.266244200Z"
    }
   },
   "id": "b6962eae45fd3980"
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-08T07:15:41.579966700Z",
     "start_time": "2023-08-08T07:15:41.443057100Z"
    }
   },
   "id": "39bea7c88e398e46"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
